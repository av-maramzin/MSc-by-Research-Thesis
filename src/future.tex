\chapter{Future work and current limitations}
\label{future-work}
\qquad The major inherent problem of the done MSc research work, is that under given timeframe it was decided to use Intel C/C++ compiler as a parallelizability expert. While ICC is pretty good in program parallelization, there are still cases, where it does not parallelize loops, which could be parallelized. If there was an ideal parallelizing expert available, then some of the red dots in the presented figures would be green, which could slightly change the results. Seoul National University implementation of NAS benchmarks has two versions of the benchmarks: sequential, and the one with added OpenMP pragmas. Ideally, these pragmas could be used as answers to the parallelizability question. It was just technically easier to use ICC compiler to get the answers.\newline  
\null\qquad While there were some little correlations between proposed metrics in their current form and loop parallelizability property, it is clear, that in order to get ideally expected correlation results (if it is principally possible to achieve it with certain precision), these metrics must be tuned, refined and probably supplemented with additional ones. In the current project state it is going to be a way easier. Working research framework has been developed in the form of PPar tool (see \ref{ppar-tool}) and surrounding scripts. All the work from C/C++ source code at the input of LLVM to the final metric figures of Python machine learning scripts has been done. PPar tool is designed in such a way, that it can be easily extended with new metrics without much efforts. Graph visualization facilities can be used to study and refine currently proposed set of metrics.\newline
\null\qquad It is possible to look at the done work from another more general angle. Computation of different numeric features lies at the basis of any machine learning technique. Some loop features have been computed in this work. These features have been examined (withing certain limits) against loop parallelizability property. The same features can be examined against different loop properties, like applicability of different loop optimizations. This work might lie on the path towards machine learning driven optimizing compilers. Apart from loops, some numeric features can be computed for different objects like program data structures, which can enable their identification by compiler.